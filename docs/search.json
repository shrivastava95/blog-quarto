[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Me",
    "section": "",
    "text": "If you are looking for a tenacious individual who\nYou do not want to miss out on working with Ishaan Shrivastava."
  },
  {
    "objectID": "about.html#my-work",
    "href": "about.html#my-work",
    "title": "About Me",
    "section": "My Work",
    "text": "My Work\nI’m part of the computer vision research team at Metafusion."
  },
  {
    "objectID": "about.html#my-interests",
    "href": "about.html#my-interests",
    "title": "About Me",
    "section": "My Interests",
    "text": "My Interests\nI am rated 1705 on codeforces, which puts me in the top 7% of codeforces competitive programmers, as well as being ranked #1 on TensorTonic, a website where you earn points by implementing machine learning algorithms.\nOutside of work, I mess around with vision-language models to make them reason faster and better. I also read blogs on lesswrong dot com, meditate, go to the gym, and fold origami."
  },
  {
    "objectID": "about.html#publications",
    "href": "about.html#publications",
    "title": "About Me",
    "section": "Publications",
    "text": "Publications\n\nLearning the Power of “No”: Foundation Models with Negations [WACV 2025 | Citations: 31]\nJaisidh Singh*, Ishaan Shrivastava*, Richa Singh, Mayank Vatsa, Aparna Bharati\n[arXiv] [GitHub] [Google Scholar]\n\nImproved compositional reasoning in VLMs via CoN-CLIP, a proposed modification to CLIP’s contrastive learning objective. Also open-sourced CC-Neg, a novel unbiased dataset to benchmark whether models understand the absence of concepts implied by negation semantics such as no, not, and without in CLIP-like VLMs. I worked on this during my undergraduate in Artificial Intelligence and Data Science @Indian Institute of Technology, Jodhpur"
  },
  {
    "objectID": "about.html#pet-projects",
    "href": "about.html#pet-projects",
    "title": "About Me",
    "section": "Pet Projects",
    "text": "Pet Projects\nRecurrent Transformer Architectures - check out my implementation of Hierarchical Reasoning Models (HRM) on GitHub.\nSpeculative Decoding - shrivastava95/specdec-minimal, an open-source package to do speculative decoding with any two models from HuggingFace. Full implementation with KV-caching! Blog out soon.\nHeavy-Tailed Self-Regularisation theory - discovered a data-free method that prunes entire layers from VLMs, with minimal loss in performance. Works by finding the best power-law coefficient that fits the eigenspectrum of the weight matrices in a layer. Work in progress with Jaisidh Singh."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Posts",
    "section": "",
    "text": "speculative-decoding\n\n\n\n\n\n\n\n\nNov 11, 2025\n\n\nIshaan Shrivastava\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/speculative-decoding/index.html#sample-tokens-until-rejection-criteria-is-met",
    "href": "posts/speculative-decoding/index.html#sample-tokens-until-rejection-criteria-is-met",
    "title": "speculative-decoding",
    "section": "sample tokens until rejection criteria is met",
    "text": "sample tokens until rejection criteria is met\n\nr1 ∼ U(0, 1), . . . , rγ ∼ U(0, 1)\nuniform_mask = torch.randn_like(prob_ratios_per_token) &gt; prob_ratios_per_token uniform_mask = torch.concat([uniform_mask, torch.ones(uniform_mask.shape[0], 1, dtype=torch.bool)]) # verifier token index, if all accept. ### n ← min({i − 1 | 1 ≤ i ≤ γ, ri &gt; pi(x) / qi(x)} ∪ {γ}) n = argmax(uniform_mask, dim=-1)"
  },
  {
    "objectID": "posts/speculative-decoding/index.html#note-that-this-implementation-is-not-batched.",
    "href": "posts/speculative-decoding/index.html#note-that-this-implementation-is-not-batched.",
    "title": "speculative-decoding",
    "section": "note that this implementation is not batched.",
    "text": "note that this implementation is not batched.\nremove_last_t_from_kvcache(past_key_values_draft, k-n)"
  }
]